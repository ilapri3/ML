{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i4u8D7qvfVR5"
   },
   "source": [
    "## Семинар 5\n",
    "\n",
    "# Тема: Масштабирование (нормализация) данных. Применение конвейера."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормализация признаков - приведение признаков к одному масштабу. Нормализация признаков относится к методам предобработки данных. Её необходимо производить в связи с тем, что многие алгоритмы машинного обучения лучше работают, когда все признаки имеют одну шкалу измерения. Деревья и леса представляют собой два алгоритма из очень немногих, где не нужно масштабировать данные. Для таких алгоритмов, которые работают независимо от масштаба признаков, хуже от нормализации обычно не становится. Нормализация применяется только к числовым признакам. Существует целый ряд методов шкалирования. Рассмотрим некоторые из них.\n",
    "\n",
    "## minmax нормализация\n",
    "\n",
    "`minmax` нормализация приводит каждый признак к значению между 0 и 1 или от a до b.  \n",
    "Признак `x` трансформируется по формуле: $${x_i}^{norm} := \\frac{x_i - x_{min}}{x_{max} - x_{min}}$$\n",
    "\n",
    "$${x_i}^{norm} := a+\\frac{(x_i - x_{min})(b-a)}{x_{max} - x_{min}}$$\n",
    "\n",
    "Класс `MinMaxScale`из библиотеки `sklearn` имеет метод `fit` для вычисления минимального ($x_{min}$) и максимального ($x_{max}$) значения признака, а метод `transform` преобразует признак по формуле. Можно выполнить обе этих операции сразу так `fit_transform`:\n",
    "\n",
    "`from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))# по умолчанию диапазон от 0 до 1\n",
    "scaler.fit_transform(X_train)\n",
    "scaler.transform(X_test)`\n",
    "\n",
    "## std нормализация (стандартная нормализация)\n",
    "\n",
    "`std` нормализация приводит каждый признак к виду нормального распределения, когда он имеет среднее значение 0 и стандартное отклонение 1.  \n",
    "Признак `x` трансформируется по формуле: $${x_i}^{st} := \\frac{x_i - x_{mean}}{x_{std}}$$\n",
    "\n",
    "Класс `StandardScaler`из библиотеки `sklearn` имеет метод `fit` для вычисления среднего значения ($x_{mean}$) признака и его стандартного отклонения ($x_{std}$), а метод `transform` преобразует признак по формуле. Можно выполнить обе этих операции сразу так `fit_transform`:\n",
    "\n",
    "`from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(X_train)\n",
    "scaler.transform(X_test)`\n",
    "\n",
    "Нормализация min-max предпочтительна, когда данные не соответствуют гауссовскому (нормальному) распределению. Нормализация min-max предпочтительна для алгоритмов, которые не следуют какому-либо распределению. Обратите внимание, что на min-max нормализацию влияют выбросы.\n",
    "\n",
    "С другой стороны, стандартная нормализация может быть полезна в тех случаях, когда данные подчиняются распределению Гаусса. Однако это не обязательно. Кроме того, в отличие от min-max нормализации, стандартная нормализация не имеет ограничивающего диапазона. Это означает, что даже если в данных есть выбросы, стандартизация на них не повлияет.\n",
    "\n",
    "### Применение конвейера\n",
    "\n",
    "Класс Pipeline позволяет писать более лаконичный код и уменьшает вероятность ошибок, которые могут быть допущены при построении цепочек операций без использования класса Pipeline (например, мы можем забыть применить все преобразования к тестовому набору или можем применить их в неправильном порядке).\n",
    "\n",
    "Класс make_pipeline - конвейер c автоматическим присваиванием имени каждому этапу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем необходимые библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import fetch_california_housing, load_diabetes\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline, make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание: \n",
    "Загрузите данные о заболевании диабетом. Масштабируйте их при помощи min-max нормализации. Обучите модель линейной регрессии на этих данных. Выведите коэффициенты гиперплоскости и метрики качества. Проделайте то же самое, используя конвейер."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068332</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031988</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6      y  \n",
       "0 -0.002592  0.019907 -0.017646  151.0  \n",
       "1 -0.039493 -0.068332 -0.092204   75.0  \n",
       "2 -0.002592  0.002861 -0.025930  141.0  \n",
       "3  0.034309  0.022688 -0.009362  206.0  \n",
       "4 -0.002592 -0.031988 -0.046641  135.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes =load_diabetes()\n",
    "X=diabetes.data\n",
    "y=diabetes.target\n",
    "df = pd.DataFrame(X, columns = diabetes.feature_names)\n",
    "df['y'] = y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделяем на обучающую и тестовую выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Масштабируем обучающие и тестовые данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модель на масштабированных данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_linreg = LinearRegression()\n",
    "model_linreg.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводим коэффициенты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  -9.42905024,  -19.89039971,  154.77853961,   74.03941014,\n",
       "       -147.22209812,   82.18680495,   -2.51359979,   35.56367877,\n",
       "        182.61282974,    7.75023385])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_linreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.133812537354288"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_linreg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем предсказание на тестовых данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model_linreg.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычислим коэффициент детерминации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35940880381777107"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2 = metrics.r2_score(y_test,y_test_pred)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE = metrics.mean_squared_error(y_test,y_test_pred) ** 0,5\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Испортируем класс Pipeline.\n",
    "\n",
    "Задаем названия и создаем объекты используемых классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "N3UjLn8UpbLs"
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps = [('scaler', MinMaxScaler()),\n",
    "                         ('lr', LinearRegression())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Шаги конвейера:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('scaler', MinMaxScaler()), ('lr', LinearRegression())]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t8AdvXjvxlux",
    "outputId": "6cc2405d-6cef-46df-90fa-7273f388a422"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, MinMaxScaler()), (&#x27;lr&#x27;, LinearRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, MinMaxScaler()), (&#x27;lr&#x27;, LinearRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', MinMaxScaler()), ('lr', LinearRegression())])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводим коэффициенты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.133812537354288"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.named_steps['lr'].intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  -9.42905024,  -19.89039971,  154.77853961,   74.03941014,\n",
       "       -147.22209812,   82.18680495,   -2.51359979,   35.56367877,\n",
       "        182.61282974,    7.75023385])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.named_steps['lr'].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем предсказание на тестовых данных. Вычислим метрики:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred=pipe.named_steps['lr'].predict(pipe.named_steps['scaler'].transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35940880381777107"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2 = metrics.r2_score(y_test,y_test_pred)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 5)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE = metrics.mean_squared_error(y_test,y_test_pred) ** 0,5\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Загрузите встроенные данные о показателе медианной стоимости дома в округах Калифорнии. Выведите описание датасета. Обозначьте за _X_ данные, а за _y_ целевую переменную. Выведите их размеры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block group\n",
      "        - HouseAge      median house age in block group\n",
      "        - AveRooms      average number of rooms per household\n",
      "        - AveBedrms     average number of bedrooms per household\n",
      "        - Population    block group population\n",
      "        - AveOccup      average number of household members\n",
      "        - Latitude      block group latitude\n",
      "        - Longitude     block group longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
      "\n",
      "The target variable is the median house value for California districts,\n",
      "expressed in hundreds of thousands of dollars ($100,000).\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "A household is a group of people residing within a home. Since the average\n",
      "number of rooms and bedrooms in this dataset are provided per household, these\n",
      "columns may take surprisingly large values for block groups with few households\n",
      "and many empty houses, such as vacation resorts.\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "houses = fetch_california_housing()\n",
    "print(houses.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = houses.data\n",
    "y = houses.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 8)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Разделите данные на обучающую и тестовую части. Выведите их размеры. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15480"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5160"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Постройте модель линейной регрессии для предсказания медианной стоимости дома в округах Калифорнии. Выведите, полученные коэффициенты  гиперплоскости. Сделайте предсказание на тестовых данных. Вычислите метрики: коэффициент детерминации и ошибка RMSE. Сделайте вывод о качестве работы модели линейной регрессии для этих данных. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = lr.coef_\n",
    "intercept = lr.intercept_\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = metrics.r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5911695436410476"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7351277481981683"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Напишите своими руками функцию MinMaxScaler_fit, которая принимает матрицу признаков, а возвращает массив минимальных значений по каждому признаку и массив максимальных значений по каждому признаку. Примените её к обучающим данным."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def  MinMaxScaler_fit(X):\n",
    "    return ....., ........"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MinMaxScaler_fit(X):\n",
    "    min_values = np.min(X, axis=0)\n",
    "    max_values = np.max(X, axis=0)\n",
    "    return min_values, max_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_values, max_values = MinMaxScaler_fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.4999    ,    1.        ,    0.84615385,    0.33333333,\n",
       "          3.        ,    0.75      ,   32.54      , -124.35      ])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.50001000e+01,  5.20000000e+01,  1.41909091e+02,  3.40666667e+01,\n",
       "        3.56820000e+04,  5.99714286e+02,  4.19500000e+01, -1.14310000e+02])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Напишите своими руками функцию _MinMaxScaler_transform_, которая принимает матрицу признаков, а также numpy-массивы минимальных и максимальных значений и возвращает масштабированные признаки. Масштабируйте обучающие и тестовые данные при помощи этой функции. \n",
    "Указание: ${x_i}^{norm} := \\frac{x_i - x_{min}}{x_{max} - x_{min}}$. Примените эту функцию к обучающим и тестовым данным, передав в неё массивы минимальных и максимальных значений обучающих данных."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def MinMaxScaler_transform(X, min, max):\n",
    "    return ......."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _MinMaxScaler_transform_(X, min_values, max_values):\n",
    "    scaled_X = (X - min_values) / (max_values - min_values)\n",
    "    return scaled_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = _MinMaxScaler_transform_(X_train, min_values, max_values)\n",
    "X_test_scaled = _MinMaxScaler_transform_(X_test, min_values, max_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.468987</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.050442</td>\n",
       "      <td>0.023842</td>\n",
       "      <td>0.053897</td>\n",
       "      <td>0.003893</td>\n",
       "      <td>0.629118</td>\n",
       "      <td>0.166335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.376188</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.040416</td>\n",
       "      <td>0.022813</td>\n",
       "      <td>0.015247</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>0.043571</td>\n",
       "      <td>0.708167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.187073</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.030918</td>\n",
       "      <td>0.026195</td>\n",
       "      <td>0.008717</td>\n",
       "      <td>0.003693</td>\n",
       "      <td>0.227418</td>\n",
       "      <td>0.605578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.447794</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.039574</td>\n",
       "      <td>0.019763</td>\n",
       "      <td>0.003279</td>\n",
       "      <td>0.003518</td>\n",
       "      <td>0.103082</td>\n",
       "      <td>0.714143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.139053</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.025401</td>\n",
       "      <td>0.020850</td>\n",
       "      <td>0.048544</td>\n",
       "      <td>0.002684</td>\n",
       "      <td>0.646121</td>\n",
       "      <td>0.292829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15475</th>\n",
       "      <td>0.269831</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.036536</td>\n",
       "      <td>0.021116</td>\n",
       "      <td>0.019872</td>\n",
       "      <td>0.004176</td>\n",
       "      <td>0.608927</td>\n",
       "      <td>0.307769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15476</th>\n",
       "      <td>0.166453</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.031923</td>\n",
       "      <td>0.017777</td>\n",
       "      <td>0.018050</td>\n",
       "      <td>0.003916</td>\n",
       "      <td>0.524973</td>\n",
       "      <td>0.344622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15477</th>\n",
       "      <td>0.186053</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.019814</td>\n",
       "      <td>0.018028</td>\n",
       "      <td>0.019647</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.429330</td>\n",
       "      <td>0.244024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15478</th>\n",
       "      <td>0.353899</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.026190</td>\n",
       "      <td>0.021663</td>\n",
       "      <td>0.029401</td>\n",
       "      <td>0.002501</td>\n",
       "      <td>0.114772</td>\n",
       "      <td>0.639442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15479</th>\n",
       "      <td>0.061261</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.021858</td>\n",
       "      <td>0.022747</td>\n",
       "      <td>0.028616</td>\n",
       "      <td>0.004485</td>\n",
       "      <td>0.027630</td>\n",
       "      <td>0.875498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15480 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  \\\n",
       "0      0.468987  0.352941  0.050442   0.023842    0.053897  0.003893   \n",
       "1      0.376188  0.333333  0.040416   0.022813    0.015247  0.002506   \n",
       "2      0.187073  0.352941  0.030918   0.026195    0.008717  0.003693   \n",
       "3      0.447794  0.235294  0.039574   0.019763    0.003279  0.003518   \n",
       "4      0.139053  0.392157  0.025401   0.020850    0.048544  0.002684   \n",
       "...         ...       ...       ...        ...         ...       ...   \n",
       "15475  0.269831  0.372549  0.036536   0.021116    0.019872  0.004176   \n",
       "15476  0.166453  0.509804  0.031923   0.017777    0.018050  0.003916   \n",
       "15477  0.186053  0.588235  0.019814   0.018028    0.019647  0.001739   \n",
       "15478  0.353899  0.647059  0.026190   0.021663    0.029401  0.002501   \n",
       "15479  0.061261  0.274510  0.021858   0.022747    0.028616  0.004485   \n",
       "\n",
       "       Latitude  Longitude  \n",
       "0      0.629118   0.166335  \n",
       "1      0.043571   0.708167  \n",
       "2      0.227418   0.605578  \n",
       "3      0.103082   0.714143  \n",
       "4      0.646121   0.292829  \n",
       "...         ...        ...  \n",
       "15475  0.608927   0.307769  \n",
       "15476  0.524973   0.344622  \n",
       "15477  0.429330   0.244024  \n",
       "15478  0.114772   0.639442  \n",
       "15479  0.027630   0.875498  \n",
       "\n",
       "[15480 rows x 8 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_scaled, columns=houses.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.251852</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.034147</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.043387</td>\n",
       "      <td>0.005728</td>\n",
       "      <td>0.004251</td>\n",
       "      <td>0.727092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.364112</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.037296</td>\n",
       "      <td>0.017621</td>\n",
       "      <td>0.036240</td>\n",
       "      <td>0.003792</td>\n",
       "      <td>0.146652</td>\n",
       "      <td>0.635458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.265431</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.036045</td>\n",
       "      <td>0.020540</td>\n",
       "      <td>0.043471</td>\n",
       "      <td>0.003606</td>\n",
       "      <td>0.649309</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.134564</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.029397</td>\n",
       "      <td>0.029157</td>\n",
       "      <td>0.010847</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.070138</td>\n",
       "      <td>0.871514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.310685</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.024621</td>\n",
       "      <td>0.020936</td>\n",
       "      <td>0.018106</td>\n",
       "      <td>0.001607</td>\n",
       "      <td>0.557917</td>\n",
       "      <td>0.191235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5155</th>\n",
       "      <td>0.244941</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.037963</td>\n",
       "      <td>0.021215</td>\n",
       "      <td>0.168138</td>\n",
       "      <td>0.004663</td>\n",
       "      <td>0.629118</td>\n",
       "      <td>0.285857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5156</th>\n",
       "      <td>0.050496</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.015710</td>\n",
       "      <td>0.024896</td>\n",
       "      <td>0.022899</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.130712</td>\n",
       "      <td>0.613546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5157</th>\n",
       "      <td>0.215838</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.019642</td>\n",
       "      <td>0.019264</td>\n",
       "      <td>0.025029</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>0.176408</td>\n",
       "      <td>0.571713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5158</th>\n",
       "      <td>0.345747</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.026563</td>\n",
       "      <td>0.016497</td>\n",
       "      <td>0.009866</td>\n",
       "      <td>0.003771</td>\n",
       "      <td>0.144527</td>\n",
       "      <td>0.598606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5159</th>\n",
       "      <td>0.294065</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.031303</td>\n",
       "      <td>0.019871</td>\n",
       "      <td>0.022310</td>\n",
       "      <td>0.003599</td>\n",
       "      <td>0.544102</td>\n",
       "      <td>0.190239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5160 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0     0.251852  0.411765  0.034147   0.022000    0.043387  0.005728  0.004251   \n",
       "1     0.364112  0.607843  0.037296   0.017621    0.036240  0.003792  0.146652   \n",
       "2     0.265431  0.549020  0.036045   0.020540    0.043471  0.003606  0.649309   \n",
       "3     0.134564  0.705882  0.029397   0.029157    0.010847  0.003333  0.070138   \n",
       "4     0.310685  0.470588  0.024621   0.020936    0.018106  0.001607  0.557917   \n",
       "...        ...       ...       ...        ...         ...       ...       ...   \n",
       "5155  0.244941  0.137255  0.037963   0.021215    0.168138  0.004663  0.629118   \n",
       "5156  0.050496  0.666667  0.015710   0.024896    0.022899  0.001411  0.130712   \n",
       "5157  0.215838  0.294118  0.019642   0.019264    0.025029  0.001897  0.176408   \n",
       "5158  0.345747  0.705882  0.026563   0.016497    0.009866  0.003771  0.144527   \n",
       "5159  0.294065  0.686275  0.031303   0.019871    0.022310  0.003599  0.544102   \n",
       "\n",
       "      Longitude  \n",
       "0      0.727092  \n",
       "1      0.635458  \n",
       "2      0.250000  \n",
       "3      0.871514  \n",
       "4      0.191235  \n",
       "...         ...  \n",
       "5155   0.285857  \n",
       "5156   0.613546  \n",
       "5157   0.571713  \n",
       "5158   0.598606  \n",
       "5159   0.190239  \n",
       "\n",
       "[5160 rows x 8 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_test_scaled, columns=houses.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Убедитесь, что у масштабированных обучающих данных минимальное значение стало равно 0, а максимальное 1. А у масштабированных тестовых данных минимальное значение стало близко к 0, а максимальное близко к 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.min(X_train_scaled, axis=0)), np.round(np.max(X_train_scaled, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.,  0.,  0.,  0.,  0., -0.,  0.,  0.]),\n",
       " array([1., 1., 0., 0., 0., 2., 1., 1.]))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.min(X_test_scaled, axis=0)), np.round(np.max(X_test_scaled, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15480.000000</td>\n",
       "      <td>15480.000000</td>\n",
       "      <td>15480.000000</td>\n",
       "      <td>15480.000000</td>\n",
       "      <td>15480.000000</td>\n",
       "      <td>15480.000000</td>\n",
       "      <td>15480.000000</td>\n",
       "      <td>15480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.232738</td>\n",
       "      <td>0.541750</td>\n",
       "      <td>0.032513</td>\n",
       "      <td>0.022602</td>\n",
       "      <td>0.039891</td>\n",
       "      <td>0.003820</td>\n",
       "      <td>0.328068</td>\n",
       "      <td>0.476480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.130664</td>\n",
       "      <td>0.247055</td>\n",
       "      <td>0.017962</td>\n",
       "      <td>0.014615</td>\n",
       "      <td>0.032078</td>\n",
       "      <td>0.011102</td>\n",
       "      <td>0.227229</td>\n",
       "      <td>0.199816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.142753</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.025577</td>\n",
       "      <td>0.019933</td>\n",
       "      <td>0.021918</td>\n",
       "      <td>0.002802</td>\n",
       "      <td>0.147715</td>\n",
       "      <td>0.253984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.210338</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.031107</td>\n",
       "      <td>0.021204</td>\n",
       "      <td>0.032624</td>\n",
       "      <td>0.003453</td>\n",
       "      <td>0.181722</td>\n",
       "      <td>0.583665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.293106</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.036926</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.048236</td>\n",
       "      <td>0.004228</td>\n",
       "      <td>0.549416</td>\n",
       "      <td>0.632470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MedInc      HouseAge      AveRooms     AveBedrms    Population  \\\n",
       "count  15480.000000  15480.000000  15480.000000  15480.000000  15480.000000   \n",
       "mean       0.232738      0.541750      0.032513      0.022602      0.039891   \n",
       "std        0.130664      0.247055      0.017962      0.014615      0.032078   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.142753      0.333333      0.025577      0.019933      0.021918   \n",
       "50%        0.210338      0.549020      0.031107      0.021204      0.032624   \n",
       "75%        0.293106      0.705882      0.036926      0.022727      0.048236   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           AveOccup      Latitude     Longitude  \n",
       "count  15480.000000  15480.000000  15480.000000  \n",
       "mean       0.003820      0.328068      0.476480  \n",
       "std        0.011102      0.227229      0.199816  \n",
       "min        0.000000      0.000000      0.000000  \n",
       "25%        0.002802      0.147715      0.253984  \n",
       "50%        0.003453      0.181722      0.583665  \n",
       "75%        0.004228      0.549416      0.632470  \n",
       "max        1.000000      1.000000      1.000000  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_scaled, columns=houses.feature_names).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Осуществите масштабирование признаков методом min-max при помощи библиотечной функции.\n",
    "Указание: Создайте объект класса [MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html). Примените к нему метод _fit_, передав в него обучающие данные, он рассчитает минимальное и максимальное значение каждого из столбцов обучающих данных. Их можно посмотреть через соответствующие атрибуты: _data_min__ и _data_max__.  Далее при помощи метода _transform_ преобразуйте обучающие и тестовые данные. Убедитесь, что они будут теми же, что и при шкалировании вручную. Для обучающих данных можно сразу применять метод _fit_transform_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Изобразите гистограммы признаков до и после min-max масштабирования."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "f, ax = plt.subplots(nrows = X.shape[1], ncols = 2, figsize=(10,15))\n",
    "f.suptitle(\"Гистограммы прихнаков до и после стандартизации\",y = 0.92,fontsize=16)\n",
    "for i in range(0,X.shape[1]):\n",
    "    ax[i][0].hist(......, bins = 15)\n",
    "    ax[i][0].set_title('Изначальное распределение',fontsize=10)\n",
    "    ax[i][0].set_xlabel(housing.feature_names[i])\n",
    "    \n",
    "    ax[i][1].hist(......., bins = 15)\n",
    "    ax[i][1].set_title('Стандартизация',fontsize=10)\n",
    "    ax[i][1].set_xlabel(housing.feature_names[i])\n",
    "f.subplots_adjust(hspace=1.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Обучите модель линейной регрессии для предсказания медианной стоимости дома в округах Калифорнии на масштабированных данных методом min-max. Выведите полученные коэффициенты  гиперплоскости. Напечатайте рядом название признака и соответствующий ему вес. Сделайте вывод о значимости признаков. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Сделайте предсказание на тестовых данных. Вычислите метрики: коэффициент детерминации и ошибка RMSE. Убедитесь, что значения метрик практически те же, что и при обучении модели на не масштабированных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Напишите своими руками функцию _StandardScaler_fit_, которая принимает матрицу признаков, а возвращает массив средних значений по каждому признаку и массив стандартных отклонений по каждому признаку. Примените её к обучающим данным."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def StandardScaler_fit(X):\n",
    "    return ....., ........"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Напишите своими руками функцию _StandardScaler_transform_, которая принимает матрицу признаков, а также numpy-массивы средних значений и стандартных отклонений и возвращает стандартизированные признаки. Стандартизируйте обучающие и тестовые данные. \n",
    "Указание: ${x_i}^{norm} := \\frac{x_i - x_{mean}}{x_{std}}$. Примените эту функцию к обучающим и тестовым данным, передав в неё массивы средних значений и стандартных отклонений обучающих данных."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def StandardScaler_transform(X, mean, std):\n",
    "    return ........."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _StandardScaler_transform_(X, mean=None, std=None):\n",
    "    if mean is None or std is None:\n",
    "        mean = np.mean(X, axis=0)\n",
    "        std = np.std(X, axis=0)\n",
    "        \n",
    "    standardized_X = (X - mean) / std\n",
    "    return standardized_X, mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_standardized, mean_train, std_train = _StandardScaler_transform_(X_train)\n",
    "X_test_standardized, _, _ = _StandardScaler_transform_(X_test, mean=mean_train, std=std_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.80812234, -0.76426232,  0.99820721, ...,  0.00657932,\n",
       "         1.32491944, -1.55220631],\n",
       "       [ 1.09789119, -0.84363104,  0.44000463, ..., -0.1183325 ,\n",
       "        -1.25207048,  1.15953974],\n",
       "       [-0.34948981, -0.76426232, -0.08879461, ..., -0.01136792,\n",
       "        -0.44296112,  0.64610253],\n",
       "       ...,\n",
       "       [-0.35730151,  0.18816232, -0.70701041, ..., -0.18746503,\n",
       "         0.44565609, -1.16338978],\n",
       "       [ 0.92730059,  0.42626848, -0.3520338 , ..., -0.11880858,\n",
       "        -0.93871598,  0.81558666],\n",
       "       [-1.31238718, -1.0817372 , -0.59321731, ...,  0.05991481,\n",
       "        -1.32222447,  1.99699073]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.14628912, -0.52615616,  0.09099757, ...,  0.1718598 ,\n",
       "        -1.42511699,  1.25425146],\n",
       "       [ 1.00547035,  0.26753104,  0.26630121, ..., -0.00253763,\n",
       "        -0.798408  ,  0.79564735],\n",
       "       [ 0.25021637,  0.02942488,  0.1966324 , ..., -0.01921117,\n",
       "         1.41378116, -1.13348082],\n",
       "       ...,\n",
       "       [-0.12933715, -1.00236848, -0.71663271, ..., -0.17318266,\n",
       "        -0.66745389,  0.4766184 ],\n",
       "       [ 0.86491257,  0.66437464, -0.33126431, ..., -0.00441821,\n",
       "        -0.80776187,  0.61120874],\n",
       "       [ 0.46936617,  0.58500592, -0.06737429, ..., -0.01991167,\n",
       "         0.95076483, -1.43257046]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_standardized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Убедитесь, что у стандартизированных обучающих данных среднее значение стало равно 0, а стандартное отклонение равно 1. А у масштабированных тестовых данных среднее значение стало близко к 0, а стандартное отклонение близко к 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = np.mean(X_train_standardized)\n",
    "train_std = np.std(X_train_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(train_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mean = np.mean(X_test_standardized)\n",
    "test_std = np.std(X_test_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(test_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Осуществите стандартизацию признаков при помощи библиотечных функций.\n",
    "Указание: Создайте объект класса [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html). Примените к нему метод _fit_, передав в него обучающие данные, он рассчитает среднее арифметическое и среднее квадратическое отклонение каждого из столбцов обучающих данных. Их можно посмотреть через соответствующие атрибуты: _mean__ и _scale__.  Далее при помощи метода _transform_ преобразуйте обучающие и тестовые данные. Убедитесь, что они будут теми же, что и при стандартизации вручную. Для обучающих данных можно сразу применять _fit_transform_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(X, random_state=0)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = np.mean(X_train_scaled, axis=0)\n",
    "train_std = np.std(X_train_scaled, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0., -0.,  0.,  0.,  0., -0.,  0., -0.])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(train_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mean = np.mean(X_test_scaled, axis=0)\n",
    "test_std = np.std(X_test_scaled, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.,  0., -0.,  0., -0.,  0.,  0., -0.])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(test_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 3., 1., 1.])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Изобразите гистограммы признаков до и после стандартизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(X_train[:, 0], bins=30, alpha=0.7, color='blue', edgecolor='black')\n",
    "plt.title('Гистограмма до стандартизации')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(X_train_scaled[:, 0], bins=30, alpha=0.7, color='green', edgecolor='black')\n",
    "plt.title('Гистограмма после стандартизации')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Обучите модель линейной регрессии для предсказания медианной стоимости дома в округах Калифорнии на стандартизированных данных. Выведите полученные коэффициенты  гиперплоскости. Напечатайте рядом название признака и соответствующий ему вес. Сделайте вывод о значимости признаков. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SfrgxrYNpzfA"
   },
   "source": [
    "### 17. Обучите модель линейной регрессии на стандартизированных данных с применением конвейера, используя класс Pipeline. Выведите полученные коэффициенты гиперплоскости. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. Сделайте предсказание на тестовых данных. Вычислите метрики: коэффициент детерминации и ошибка RMSE. Убедитесь, что они получились те же, что и без применения конвейера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3NBWFAZFpUqG"
   },
   "source": [
    "### 19. Обучите модель линейной регрессии на стандартизированных данных с применением конвейера, используя класс make_pipeline. Выведите полученные коэффициенты гиперплоскости. Сделайте предсказание на тестовых данных и вычислите метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Ht8ktXHoHjqa",
    "FzcPKtyIHnG6",
    "wHjLvAaQSfOQ",
    "SfrgxrYNpzfA"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
